
### Project
 <p>In this project will process the event_datafile_new.csv dataset to create a denormalized dataset</p>
 <p>1.model the data tables keeping in mind the queries you need to run</p>
 <p>2.provide queries that you will need to model your data tables for</p>
 <p>3.load the data into tables created in Apache Cassandra and run queries</p>

  ### Project Steps
 <p>Modeling NoSQL database or Apache Cassandra database</p>
 <p>Design tables to answer the queries outlined in the project template</p>
 <p>Write Apache Cassandra CREATE KEYSPACE and SET KEYSPACE statements</p>
 <p>Develop your CREATE statement for each of the tables to address each question</p>
 <p>Load the data with INSERT statement for each of the tables</p>
 <p>Build ETL Pipeline</p>
 <p>Implement the logic in section Part I of the notebook template to iterate through each event file in event_data to process and create a new CSV file in Python</p>
 <p>Make necessary edits to Part II of the notebook template to include Apache Cassandra CREATE and INSERT statements to load processed records into relevant tables in  data model</p>

